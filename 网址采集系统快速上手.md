# 网址采集系统 - 快速上手指南

## 🎉 系统已成功安装!

所有测试已通过,系统可以正常使用。

## 📋 功能概述

这个系统可以让你:
1. ✅ **配置多个网址数据源** - 从不同网站采集预测数据
2. ✅ **自动采集预测数据** - 支持号码和生肖两种类型
3. ✅ **灵活配置提取规则** - CSS选择器、正则表达式、XPath三种方式
4. ✅ **自动验证准确性** - 开奖后自动判断预测对错
5. ✅ **统计分析报表** - 查看各采集源的准确率

## 🚀 快速开始(5分钟上手)

### 步骤1: 启动系统

```bash
# 方法1: 使用launcher(推荐)
python launcher.py

# 方法2: 使用批处理文件
一键启动.bat

# 方法3: 手动启动
cd backend
python main.py
```

启动成功后,你会看到:
```
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 步骤2: 访问API管理界面

在浏览器打开: **http://localhost:8000/docs**

你会看到所有可用的API接口,包括新增的"网址采集"标签。

### 步骤3: 添加第一个采集源

#### 方式A: 使用API文档界面

1. 在 http://localhost:8000/docs 找到 `POST /api/web_collect/sources`
2. 点击 "Try it out"
3. 输入配置:

```json
{
  "name": "我的测试采集源",
  "url": "https://你要采集的网站.com/predict",
  "lottery_type": "am",
  "data_type": "numbers",
  "extract_config": {
    "method": "css",
    "selector": "div.predict-numbers span",
    "period_pattern": "(\\d{7})"
  },
  "is_active": true,
  "description": "测试采集源"
}
```

4. 点击 "Execute"

#### 方式B: 使用curl命令

```bash
curl -X POST "http://localhost:8000/api/web_collect/sources" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "我的测试采集源",
    "url": "https://你要采集的网站.com/predict",
    "lottery_type": "am",
    "data_type": "numbers",
    "extract_config": {
      "method": "css",
      "selector": "div.predict-numbers span",
      "period_pattern": "(\\d{7})"
    },
    "is_active": true
  }'
```

### 步骤4: 执行采集

```bash
# 方法1: API文档界面
# 找到 POST /api/web_collect/execute_all 并执行

# 方法2: curl命令
curl -X POST "http://localhost:8000/api/web_collect/execute_all"
```

### 步骤5: 查看采集结果

```bash
# API文档界面
# 找到 GET /api/web_collect/results 并执行

# curl命令
curl "http://localhost:8000/api/web_collect/results?page=1"
```

### 步骤6: 等待开奖自动验证

当系统采集到开奖数据时,会自动触发验证。

也可以手动触发验证:
```bash
curl -X POST "http://localhost:8000/api/web_collect/verify_all"
```

### 步骤7: 查看统计数据

```bash
curl "http://localhost:8000/api/web_collect/stats"
```

## 📝 配置采集源的技巧

### 如何找到正确的CSS选择器?

1. 打开要采集的网页
2. 按F12打开开发者工具
3. 点击左上角的选择工具(箭头图标)
4. 点击页面上要采集的数据
5. 在开发者工具中右键点击高亮的HTML元素
6. 选择 "Copy" -> "Copy selector"

### 常见配置示例

#### 示例1: 采集号码(CSS选择器)
```json
{
  "method": "css",
  "selector": "div.numbers span.num",
  "period_selector": "div.period",
  "period_pattern": "第(\\d+)期"
}
```

#### 示例2: 采集生肖(正则表达式)
```json
{
  "method": "regex",
  "pattern": "预测生肖[:：]\\s*([鼠牛虎兔龙蛇马羊猴鸡狗猪,，、]+)",
  "period_pattern": "(\\d{7})"
}
```

#### 示例3: 采集表格数据(XPath)
```json
{
  "method": "xpath",
  "xpath": "//table[@class='predict']//td[@class='number']/text()",
  "period_pattern": "(\\d{7})"
}
```

## 🔍 常见问题

### Q: 采集失败怎么办?

**A: 检查清单:**
1. ✅ 网址是否能正常访问?
2. ✅ CSS选择器是否正确?
3. ✅ 网站是否有反爬虫机制?
4. ✅ 查看后端控制台日志输出

### Q: 验证不准确?

**A: 可能原因:**
- 期号格式不一致(应为7位数字,如 "2025198")
- 数据类型不匹配(采集的是号码但设置成了生肖)
- 开奖数据尚未录入系统

### Q: 如何提高准确率?

**A: 建议:**
1. 确保提取配置精确匹配网页结构
2. 添加多个采集源进行对比
3. 定期检查网站是否更新了页面结构

### Q: 可以定时自动采集吗?

**A:** 可以!有两种方式:
1. 将采集任务添加到系统的定时调度器(scheduler)
2. 使用系统的cron或Windows任务计划程序定时调用API

## 📊 文件结构

```
backend/
├── services/
│   ├── web_collector.py          # 采集服务(~400行)
│   └── result_verifier.py        # 验证服务(~300行)
├── routes/
│   └── web_collect.py            # API路由(~600行)
├── init_web_collect_tables.py    # 数据库初始化
├── test_web_collect.py           # 功能测试脚本
└── WEB_COLLECT_README.md         # 详细文档

frontend/
└── modules/
    └── web_collect.js            # 前端模块(~500行)

数据库表:
├── collect_sources               # 采集源配置表
└── collected_data                # 采集结果表
```

## 🎯 下一步建议

1. **添加真实采集源** - 替换示例配置为实际网址
2. **测试采集流程** - 执行采集并检查结果
3. **监控准确率** - 定期查看统计数据
4. **优化配置** - 根据结果调整提取规则

## 📚 更多文档

- **详细API文档**: http://localhost:8000/docs
- **完整使用说明**: backend/WEB_COLLECT_README.md
- **功能测试**: 运行 `python backend/test_web_collect.py`

## 💡 提示

- 采集源默认是禁用的,记得启用(`is_active: true`)
- 期号必须是7位数字格式
- 建议先测试CSS选择器是否正确再启用自动采集
- 查看后端控制台可以看到详细的采集日志

## 🆘 需要帮助?

如遇问题:
1. 查看后端控制台日志
2. 运行测试脚本: `python backend/test_web_collect.py`
3. 检查数据库表是否正确创建
4. 访问API文档测试各个接口

---

**祝你使用愉快!** 🎊

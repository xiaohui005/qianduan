#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ•´ç†å·¥ç¨‹å¸ˆè¾…åŠ©å·¥å…·
ç”¨äºè‡ªåŠ¨æ£€æŸ¥é¡¹ç›®è§„èŒƒã€ç”Ÿæˆæ•´ç†æŠ¥å‘Š
"""
import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Tuple
import json

# è®¾ç½®Windowsæ§åˆ¶å°UTF-8ç¼–ç 
if sys.platform == 'win32':
    try:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
    except Exception:
        pass  # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç¼–ç 


class ProjectOrganizer:
    """é¡¹ç›®æ•´ç†å·¥ç¨‹å¸ˆ"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.issues = []
        self.warnings = []
        self.suggestions = []

    def check_file_size(self) -> List[Dict]:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¬¦åˆè§„èŒƒ"""
        print("ğŸ“ æ£€æŸ¥æ–‡ä»¶å¤§å°...")
        oversized_files = []

        # æ£€æŸ¥Pythonæ–‡ä»¶ï¼ˆé™åˆ¶800è¡Œï¼‰
        for py_file in self.project_root.rglob("*.py"):
            if "venv" in str(py_file) or "__pycache__" in str(py_file):
                continue

            lines = len(py_file.read_text(encoding='utf-8', errors='ignore').splitlines())
            if lines > 800:
                oversized_files.append({
                    'file': str(py_file.relative_to(self.project_root)),
                    'lines': lines,
                    'limit': 800,
                    'type': 'Python',
                    'severity': 'warning' if lines < 1500 else 'error'
                })

        # æ£€æŸ¥JavaScriptæ–‡ä»¶ï¼ˆé™åˆ¶800è¡Œï¼‰
        for js_file in self.project_root.rglob("*.js"):
            if "node_modules" in str(js_file):
                continue

            lines = len(js_file.read_text(encoding='utf-8', errors='ignore').splitlines())
            if lines > 800:
                oversized_files.append({
                    'file': str(js_file.relative_to(self.project_root)),
                    'lines': lines,
                    'limit': 800,
                    'type': 'JavaScript',
                    'severity': 'warning' if lines < 1500 else 'error'
                })

        return oversized_files

    def check_utils_usage(self) -> List[Dict]:
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å·¥å…·ç®±å‡½æ•°"""
        print("ğŸ”§ æ£€æŸ¥å·¥å…·ç®±ä½¿ç”¨æƒ…å†µ...")
        issues = []

        # éœ€è¦æ£€æŸ¥çš„æ¨¡å¼
        patterns = [
            {
                'pattern': r'def\s+(plus49_wrap|minus49_wrap)\s*\(',
                'message': 'å‘ç°é‡å¤å®šä¹‰å¾ªç¯å‡½æ•°ï¼Œåº”ä½¿ç”¨ backend.utils.wrap_in_range',
                'severity': 'warning'
            },
            {
                'pattern': r'conn\s*=\s*get_connection\(\)',
                'message': 'åº”ä½¿ç”¨ backend.utils.get_db_cursor() ä¸Šä¸‹æ–‡ç®¡ç†å™¨',
                'severity': 'error'
            },
            {
                'pattern': r'cursor\s*=\s*conn\.cursor',
                'message': 'åº”ä½¿ç”¨ backend.utils.get_db_cursor() ä¸Šä¸‹æ–‡ç®¡ç†å™¨',
                'severity': 'warning'
            }
        ]

        for py_file in self.project_root.rglob("backend/**/*.py"):
            if "__pycache__" in str(py_file):
                continue

            try:
                content = py_file.read_text(encoding='utf-8')
                for pattern_info in patterns:
                    matches = re.finditer(pattern_info['pattern'], content)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        issues.append({
                            'file': str(py_file.relative_to(self.project_root)),
                            'line': line_num,
                            'message': pattern_info['message'],
                            'severity': pattern_info['severity']
                        })
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {py_file}: {e}")

        return issues

    def check_code_duplication(self) -> List[Dict]:
        """æ£€æŸ¥ä»£ç é‡å¤ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
        print("ğŸ” æ£€æŸ¥ä»£ç é‡å¤...")
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„é‡å¤ä»£ç æ£€æµ‹å·¥å…·
        # ç›®å‰åªåšç®€å•çš„å‡½æ•°åæ£€æµ‹
        duplicates = []
        function_names = {}

        for py_file in self.project_root.rglob("backend/**/*.py"):
            if "__pycache__" in str(py_file) or "utils" in str(py_file):
                continue

            try:
                content = py_file.read_text(encoding='utf-8')
                # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
                for match in re.finditer(r'def\s+(\w+)\s*\(', content):
                    func_name = match.group(1)
                    if func_name.startswith('_'):  # è·³è¿‡ç§æœ‰å‡½æ•°
                        continue

                    if func_name in function_names:
                        duplicates.append({
                            'function': func_name,
                            'files': [function_names[func_name], str(py_file.relative_to(self.project_root))],
                            'message': f'å‡½æ•° {func_name} åœ¨å¤šä¸ªæ–‡ä»¶ä¸­å®šä¹‰ï¼Œè€ƒè™‘æå–åˆ°å·¥å…·ç®±'
                        })
                    else:
                        function_names[func_name] = str(py_file.relative_to(self.project_root))
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {py_file}: {e}")

        return duplicates

    def check_import_statements(self) -> List[Dict]:
        """æ£€æŸ¥å¯¼å…¥è¯­å¥è§„èŒƒ"""
        print("ğŸ“¦ æ£€æŸ¥å¯¼å…¥è¯­å¥...")
        issues = []

        for py_file in self.project_root.rglob("backend/**/*.py"):
            if "__pycache__" in str(py_file):
                continue

            try:
                content = py_file.read_text(encoding='utf-8')
                lines = content.splitlines()

                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥æ˜¯å¦ç›´æ¥å¯¼å…¥db.pyè€Œä¸æ˜¯utils
                    if re.search(r'from\s+backend\.db\s+import\s+get_connection', line):
                        issues.append({
                            'file': str(py_file.relative_to(self.project_root)),
                            'line': i,
                            'message': 'åº”ä½¿ç”¨ from backend.utils import get_db_cursor',
                            'severity': 'warning'
                        })
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {py_file}: {e}")

        return issues

    def generate_report(self) -> str:
        """ç”Ÿæˆæ•´ç†æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ é¡¹ç›®æ•´ç†æŠ¥å‘Š")
        print("="*60 + "\n")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        oversized = self.check_file_size()
        if oversized:
            print(f"âš ï¸  å‘ç° {len(oversized)} ä¸ªè¶…å¤§æ–‡ä»¶ï¼š")
            for item in oversized:
                icon = "ğŸ”´" if item['severity'] == 'error' else "ğŸŸ¡"
                print(f"  {icon} {item['file']}: {item['lines']}è¡Œ (é™åˆ¶{item['limit']}è¡Œ)")
            print()
        else:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å¤§å°ç¬¦åˆè§„èŒƒ\n")

        # æ£€æŸ¥å·¥å…·ç®±ä½¿ç”¨
        utils_issues = self.check_utils_usage()
        if utils_issues:
            print(f"âš ï¸  å‘ç° {len(utils_issues)} å¤„æœªä½¿ç”¨å·¥å…·ç®±çš„ä»£ç ï¼š")
            for item in utils_issues:
                icon = "ğŸ”´" if item['severity'] == 'error' else "ğŸŸ¡"
                print(f"  {icon} {item['file']}:{item['line']}")
                print(f"     {item['message']}")
            print()
        else:
            print("âœ… å·¥å…·ç®±ä½¿ç”¨è§„èŒƒ\n")

        # æ£€æŸ¥å¯¼å…¥è¯­å¥
        import_issues = self.check_import_statements()
        if import_issues:
            print(f"âš ï¸  å‘ç° {len(import_issues)} å¤„å¯¼å…¥è¯­å¥é—®é¢˜ï¼š")
            for item in import_issues:
                print(f"  ğŸŸ¡ {item['file']}:{item['line']}")
                print(f"     {item['message']}")
            print()
        else:
            print("âœ… å¯¼å…¥è¯­å¥è§„èŒƒ\n")

        # æ£€æŸ¥ä»£ç é‡å¤
        duplicates = self.check_code_duplication()
        if duplicates:
            print(f"ğŸ’¡ å‘ç° {len(duplicates)} å¤„å¯èƒ½çš„ä»£ç é‡å¤ï¼š")
            for item in duplicates[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  â„¹ï¸  {item['message']}")
                print(f"     æ–‡ä»¶: {', '.join(item['files'])}")
            if len(duplicates) > 5:
                print(f"  ... è¿˜æœ‰ {len(duplicates) - 5} å¤„")
            print()
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾çš„ä»£ç é‡å¤\n")

        # æ€»ç»“
        print("="*60)
        total_issues = len(oversized) + len(utils_issues) + len(import_issues)
        if total_issues == 0:
            print("ğŸ‰ é¡¹ç›®æ•´ç†æ£€æŸ¥é€šè¿‡ï¼ä»£ç è´¨é‡è‰¯å¥½ã€‚")
        else:
            print(f"ğŸ“Š å…±å‘ç° {total_issues} ä¸ªéœ€è¦æ”¹è¿›çš„åœ°æ–¹")
            print("ğŸ’¡ å»ºè®®ï¼š")
            if oversized:
                print("   - æ‹†åˆ†è¶…å¤§æ–‡ä»¶ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§")
            if utils_issues:
                print("   - ä½¿ç”¨å·¥å…·ç®±å‡½æ•°ï¼Œé¿å…ä»£ç é‡å¤")
            if import_issues:
                print("   - è§„èŒƒå¯¼å…¥è¯­å¥ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·æ¨¡å—")
        print("="*60)

        return {
            'oversized_files': oversized,
            'utils_issues': utils_issues,
            'import_issues': import_issues,
            'duplicates': duplicates,
            'total_issues': total_issues
        }


def main():
    """ä¸»å‡½æ•°"""
    organizer = ProjectOrganizer()
    report = organizer.generate_report()

    # ä¿å­˜æŠ¥å‘Šåˆ°JSON
    report_file = Path("project_organization_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    return report['total_issues']


if __name__ == "__main__":
    exit_code = main()
    exit(0 if exit_code == 0 else 1)
